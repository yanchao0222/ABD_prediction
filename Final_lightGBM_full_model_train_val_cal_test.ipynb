{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, KFold\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "from scipy.misc import derivative\n",
    "from sklearn.metrics import average_precision_score\n",
    "import joblib\n",
    "import shap\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "\n",
    "Youden = True\n",
    "RAND_TIME = 30\n",
    "BIN = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp = np.load('./data/T_MIND_new_data_prepare_without_dem_worst_no_norm_add_features.npy',allow_pickle=True)\n",
    "data_temp = [i for i in data_temp]\n",
    "dem_temp = np.load('./data/T_MIND_new_data_prepare_dem_instance_wise_worst_no_norm_add_features.npy',allow_pickle=True)\n",
    "dem_temp = [i for i in dem_temp]\n",
    "label_temp = np.load('./data/T_MIND_new_label_prepare_normal_worst_no_norm_add_features.npy',allow_pickle=True)\n",
    "label_temp = [i for i in label_temp]\n",
    "\n",
    "random.seed(0)\n",
    "index_list = [i for i in range(len(data_temp))]\n",
    "random.shuffle(index_list)\n",
    "data = []\n",
    "dem = []\n",
    "label = []\n",
    "\n",
    "for i in index_list:\n",
    "    data.append(data_temp[i])\n",
    "    dem.append(dem_temp[i])\n",
    "    label.append(label_temp[i])\n",
    "\n",
    "data = np.array(data)\n",
    "dem = np.array(dem)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "random_index_list = []\n",
    "for rand_id in range(RAND_TIME):\n",
    "    index_list = [i for i in range(len(data_temp))]\n",
    "    random.shuffle(index_list)\n",
    "    random_index_list.append(index_list)\n",
    "# random_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECE_value(confidences, labels, bins):\n",
    "    bin_boundaries = np.linspace(0, 1, bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "#     accuracies = predictions==labels\n",
    "    ece = 0\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        # Calculated |confidence - accuracy| in each bin\n",
    "        in_bin = (confidences >=bin_lower) * (confidences <=(bin_upper))\n",
    "        prop_in_bin = in_bin.mean()\n",
    "        if prop_in_bin > 0:\n",
    "            positive_in_bin = labels[in_bin].mean()\n",
    "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "            ece += abs(avg_confidence_in_bin - positive_in_bin) * prop_in_bin\n",
    "    return ece\n",
    "\n",
    "# def focal_loss_lgb(y_pred, dtrain, alpha, gamma):\n",
    "#     a,g = alpha, gamma\n",
    "#     y_true = dtrain.label\n",
    "#     def fl(x,t):\n",
    "#         p = 1/(1+np.exp(-x))\n",
    "#         return -( a*t + (1-a)*(1-t) ) * (( 1 - ( t*p + (1-t)*(1-p)) )**g) * ( t*np.log(p)+(1-t)*np.log(1-p) )\n",
    "#     partial_fl = lambda x: fl(x, y_true)\n",
    "#     grad = derivative(partial_fl, y_pred, n=1, dx=1e-6)\n",
    "#     hess = derivative(partial_fl, y_pred, n=2, dx=1e-6)\n",
    "#     return grad, hess\n",
    "\n",
    "# def focal_loss_lgb_eval_error(y_pred, dtrain, alpha, gamma):\n",
    "#     a,g = alpha, gamma\n",
    "#     y_true = dtrain.label\n",
    "#     p = 1/(1+np.exp(-y_pred))\n",
    "#     loss = -( a*y_true + (1-a)*(1-y_true) ) * (( 1 - ( y_true*p + (1-y_true)*(1-p)) )**g) * ( y_true*np.log(p)+(1-y_true)*np.log(1-p) )\n",
    "#     return 'focal_loss', np.mean(loss), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************************* SPLIT 0 **************************\n",
      "\n",
      "923\n",
      "103\n",
      "738\n",
      "185\n",
      "\n",
      "************************* CV Fold 0 **************************\n",
      "\n",
      "[LightGBM] [Warning] seed is set=0, random_state=0 will be ignored. Current value: seed=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using categorical_feature in Dataset.\n",
      "categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368]\n",
      "Overriding the parameters from Reference Dataset.\n",
      "categorical_column in param dict is overridden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[792]\tvalid_0's binary_logloss: 0.28665\n",
      "Validation AUROC: 0.8139, PRAUC: 0.4077, ACC: 0.6792, PPV: 0.2394, NPV: 0.9647, Sensitivity: 0.8148, Specificity: 0.6615. Best threshold 0.0868\n",
      "| TN: 1229 (785/444) | FP: 629 (239/390) | FN: 45 (32/13) | TP: 198 (60/138) | Total: 2101\n",
      "Before Calibration:   Test AUROC: 0.8567, PRAUC: 0.4784, ACC: 0.6901, PPV: 0.2660, NPV: 0.9693, Sensitivity: 0.8509, Specificity: 0.6673, FP_3rd_day_acc: 0.1852\n",
      "| TN: 758 (411/347) | FP: 378 (164/214) | FN: 24 (18/6) | TP: 137 (37/100) | Total: 1297\n",
      "ECE Loss Before Calibration: 0.08390537\n",
      "After Calibration:   Test AUROC: 0.8527, PRAUC: 0.4383, ACC: 0.6901, PPV: 0.2660, NPV: 0.9693, Sensitivity: 0.8509, Specificity: 0.6673, Best threshold: 0.1203\n",
      "| TN: 758 (411/347) | FP: 378 (164/214) | FN: 24 (18/6) | TP: 137 (37/100) | Total: 1297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE Loss After Calibration: 0.08559257\n",
      "738\n",
      "185\n",
      "\n",
      "************************* CV Fold 1 **************************\n",
      "\n",
      "[LightGBM] [Warning] seed is set=0, random_state=0 will be ignored. Current value: seed=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using categorical_feature in Dataset.\n",
      "categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368]\n",
      "Overriding the parameters from Reference Dataset.\n",
      "categorical_column in param dict is overridden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-655cc31791b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mcat_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m76\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m77\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m78\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m79\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m81\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m82\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m83\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m85\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m86\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m87\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m88\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m89\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m91\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m92\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m93\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m94\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m97\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m98\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m102\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m103\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m104\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m105\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m106\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m107\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m108\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m109\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m110\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m113\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m114\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m115\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m116\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m117\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m118\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m119\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m121\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m122\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m124\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m125\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m126\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m127\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m129\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m130\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m131\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m132\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m133\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m134\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m135\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m136\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m137\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m138\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m139\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m140\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m141\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m142\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m143\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m144\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m145\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m146\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m147\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m148\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m149\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m151\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m152\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m153\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m154\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m155\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m156\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m157\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m158\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m159\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m161\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m162\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m163\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m164\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m165\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m166\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m167\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m168\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m169\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m170\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m171\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m172\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m173\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m174\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m175\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m176\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m177\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m178\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m179\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m181\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m182\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m183\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m184\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m185\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m186\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m187\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m188\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m189\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m190\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m191\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m192\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m193\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m194\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m195\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m196\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m197\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m198\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m199\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m201\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m202\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m203\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m204\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m205\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m206\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m207\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m208\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m209\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m210\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m211\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m212\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m213\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m214\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m215\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m216\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m217\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m218\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m219\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m220\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m221\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m222\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m223\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m225\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m226\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m227\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m228\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m229\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m230\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m231\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m232\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m233\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m234\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m235\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m257\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m258\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m259\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m260\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m261\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m262\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m263\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m264\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m265\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m266\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m267\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m268\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m269\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m270\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m271\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m272\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m273\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m274\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m275\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m276\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m277\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m278\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m279\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m280\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m281\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m282\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m283\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m284\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m285\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m286\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m287\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m288\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m289\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m290\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m291\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m292\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m293\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m294\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m295\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m296\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m297\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m298\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m301\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m302\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m303\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m304\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m305\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m306\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m307\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m308\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m309\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m310\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m311\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m312\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m313\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m314\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m315\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m316\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m317\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m318\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m319\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m321\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m322\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m323\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m324\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m325\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m326\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m327\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m328\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m329\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m330\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m331\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m332\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m333\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m334\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m335\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m336\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m337\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m338\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m339\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m340\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m341\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m342\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m343\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m344\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m345\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m346\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m347\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m348\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m349\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m350\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m351\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m352\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m353\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m354\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m355\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m356\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m357\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m358\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m359\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m360\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m361\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m362\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m363\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m364\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m365\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m366\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m367\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m368\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_label_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/xm/env/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    836\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                                         callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    839\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/xm/env/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    598\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                               callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/xm/env/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/xm/env/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2370\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   2371\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2372\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   2373\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_auroc_result = []\n",
    "final_prauc_result = []\n",
    "final_acc_result = []\n",
    "final_ppv_result = []\n",
    "final_npv_result = []\n",
    "final_sens_result = []\n",
    "final_spes_result = []\n",
    "\n",
    "final_tn_result = []\n",
    "final_fp_result = []\n",
    "final_fn_result = []\n",
    "final_tp_result = []\n",
    "\n",
    "final_TN_last_N_result = []\n",
    "final_TN_last_AB_result = []\n",
    "final_FP_last_N_result = []\n",
    "final_FP_last_AB_result = []\n",
    "final_FN_last_N_result = []\n",
    "final_FN_last_AB_result = []\n",
    "final_TP_last_N_result = []\n",
    "final_TP_last_AB_result = []\n",
    "\n",
    "final_best_threshold_list_val = []\n",
    "\n",
    "final_ece_loss_before_cal = []\n",
    "final_ece_loss_after_cal = []\n",
    "final_3rd_day_acc_in_FP = []   \n",
    "\n",
    "\n",
    "\n",
    "SPLIT = 0\n",
    "for random_split in random_index_list:\n",
    "    \n",
    "    print(\"\\n************************* SPLIT %d **************************\\n\" % SPLIT)\n",
    "        \n",
    "    train_val_index = random_split[:int(0.90*len(random_split))]\n",
    "    test_index = random_split[int(0.90*len(random_split)):]\n",
    "#     print(len(train_val_index))\n",
    "#     print(len(test_index))\n",
    "\n",
    "    train_val_data = []\n",
    "    train_val_dem = []\n",
    "    train_val_label = []\n",
    "    for ind in train_val_index:\n",
    "        train_val_data.extend([data[ind]])\n",
    "        train_val_dem.extend([dem[ind]])\n",
    "        train_val_label.extend([label[ind]])\n",
    "\n",
    "    test_data = []\n",
    "    test_dem = []\n",
    "    test_label = []\n",
    "    patient_indicator = []       \n",
    "    ind_ = 0         \n",
    "    for ind in test_index:\n",
    "        test_data.extend([data[ind]])\n",
    "        test_dem.extend([dem[ind]])\n",
    "        test_label.extend([label[ind]])\n",
    "        patient_indicator.extend([ind_]*len(label[ind]))       \n",
    "        ind_ += 1       \n",
    "\n",
    "    test_data = [i for i in test_data]\n",
    "    test_data_temp = np.array([j for sub in test_data for j in sub])\n",
    "    test_data_temp = test_data_temp[:, -1, :]\n",
    "    test_dem = [i for i in test_dem]\n",
    "    test_dem_temp = np.array([j for sub in test_dem for j in sub])\n",
    "    test_label = [i for i in test_label]\n",
    "    test_label_temp = np.array([j for sub in test_label for j in sub])\n",
    "\n",
    "    test_temp = np.concatenate((test_data_temp, test_dem_temp), axis=1)\n",
    "\n",
    "    auroc_result = []\n",
    "    prauc_result = []\n",
    "    acc_result = []\n",
    "    ppv_result = []\n",
    "    npv_result = []\n",
    "    sens_result = []\n",
    "    spes_result = []\n",
    "\n",
    "    tn_result = []\n",
    "    fp_result = []\n",
    "    fn_result = []\n",
    "    tp_result = []\n",
    "\n",
    "    TN_last_N_result = []\n",
    "    TN_last_AB_result = []\n",
    "    FP_last_N_result = []\n",
    "    FP_last_AB_result = []\n",
    "    FN_last_N_result = []\n",
    "    FN_last_AB_result = []\n",
    "    TP_last_N_result = []\n",
    "    TP_last_AB_result = []\n",
    "\n",
    "    best_threshold_list_val = []\n",
    "\n",
    "    ece_loss_before_cal = []\n",
    "    ece_loss_after_cal = []\n",
    "    \n",
    "    third_day_acc_in_FP = []  \n",
    "\n",
    "    kf_inner = KFold(n_splits=5)\n",
    "    kf_inner.get_n_splits(train_val_data)\n",
    "    fold = 0\n",
    "    for train_index, val_index in kf_inner.split(train_val_data):\n",
    "        print(len(train_index))\n",
    "        print(len(val_index))\n",
    "\n",
    "        train_data = []\n",
    "        train_dem = []\n",
    "        train_label = []\n",
    "        for ind in train_index:\n",
    "            train_data.extend([train_val_data[ind]])\n",
    "            train_dem.extend([train_val_dem[ind]])\n",
    "            train_label.extend([train_val_label[ind]])\n",
    "\n",
    "        val_data = []\n",
    "        val_dem = []\n",
    "        val_label = []\n",
    "        for ind in val_index:\n",
    "            val_data.extend([train_val_data[ind]])\n",
    "            val_dem.extend([train_val_dem[ind]])\n",
    "            val_label.extend([train_val_label[ind]])\n",
    "\n",
    "\n",
    "        train_data = [i for i in train_data]\n",
    "        train_data_temp = np.array([j for sub in train_data for j in sub])\n",
    "        train_data_temp = train_data_temp[:, -1, :]\n",
    "        train_dem = [i for i in train_dem]\n",
    "        train_dem_temp = np.array([j for sub in train_dem for j in sub])\n",
    "        train_label = [i for i in train_label]\n",
    "        train_label_temp = np.array([j for sub in train_label for j in sub])\n",
    "        train_temp = np.concatenate((train_data_temp, train_dem_temp), axis=1)\n",
    "\n",
    "        val_data = [i for i in val_data]\n",
    "        val_data_temp = np.array([j for sub in val_data for j in sub])\n",
    "        val_data_temp = val_data_temp[:, -1, :]\n",
    "        val_dem = [i for i in val_dem]\n",
    "        val_dem_temp = np.array([j for sub in val_dem for j in sub])\n",
    "        val_label = [i for i in val_label]\n",
    "        val_label_temp = np.array([j for sub in val_label for j in sub])\n",
    "        val_temp = np.concatenate((val_data_temp, val_dem_temp), axis=1)\n",
    "\n",
    "        print(\"\\n************************* CV Fold %d **************************\\n\" % fold)\n",
    "\n",
    "\n",
    "        gbm = lgb.LGBMClassifier(n_estimators = 3000,\n",
    "                         boosting_type = 'gbdt',\n",
    "                         colsample_bytree = 0.300000000000001,\n",
    "                         learning_rate = 0.005,\n",
    "                         max_depth = 10,\n",
    "                         min_child_samples = 5, \n",
    "                         min_child_weight = 5,\n",
    "                         min_split_gain = 0.0,\n",
    "                         n_jobs = -1,\n",
    "                         num_leaves = 40,\n",
    "                         objective = 'binary',\n",
    "                         random_state = 0,\n",
    "                         seed = 0,\n",
    "                         reg_alpha = 0.0030559559479313415,\n",
    "                         reg_lambda = 1.0949294490500017e-06, \n",
    "                         subsample = 0.9,\n",
    "                         subsample_for_bin = 200000,\n",
    "                         subsample_freq = 4,\n",
    "                         verbose = -1,\n",
    "                         metric = 'binary_logloss', scale_pos_weight=1)\n",
    "\n",
    "        cat_idxs = [75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368]\n",
    "        max_epochs = 3000\n",
    "        gbm.fit(train_temp, abs(train_label_temp), eval_set=[(val_temp, abs(val_label_temp))],early_stopping_rounds=300, categorical_feature = cat_idxs, verbose=-1)\n",
    "\n",
    "\n",
    "        ##### vaildation evaluation\n",
    "\n",
    "        y_scores = gbm.predict_proba(val_temp)\n",
    "        y_scores = y_scores[:,1]\n",
    "        fpr, tpr, threshold = roc_curve(abs(val_label_temp), y_scores, pos_label=1)\n",
    "        max_ = 0\n",
    "        pos = 0\n",
    "        thres = 0\n",
    "        for i in range(len(fpr)):\n",
    "            sensitivity = tpr[i]\n",
    "            specificity = 1 - fpr[i]\n",
    "            if sensitivity + specificity - 1 > max_:\n",
    "                thres = threshold[i]\n",
    "                max_ = sensitivity + specificity - 1\n",
    "                pos = i\n",
    "        if Youden == False:\n",
    "            thres = 0.5\n",
    "        pred_y = [0.0] * len(y_scores)\n",
    "        for ind, value in enumerate(y_scores):\n",
    "            if value >= thres:\n",
    "                pred_y[ind] = 1.0\n",
    "        pred_y = np.array(pred_y)\n",
    "\n",
    "        auroc = roc_auc_score(y_score=y_scores, y_true=abs(val_label_temp))\n",
    "        prauc = average_precision_score(abs(val_label_temp), y_scores)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(abs(val_label_temp), pred_y).ravel()\n",
    "        ppv = tp / (tp + fp)\n",
    "        npv = tn / (tn + fn)\n",
    "        sens = tp / (tp + fn)\n",
    "        spes = tn / (tn + fp)\n",
    "        acc = (tn + tp) / (tn + fp + fn + tp)\n",
    "\n",
    "        FP_last_N = 0\n",
    "        FP_last_AB = 0\n",
    "        FN_last_N = 0\n",
    "        FN_last_AB = 0\n",
    "        TP_last_N = 0\n",
    "        TP_last_AB = 0\n",
    "        TN_last_N = 0\n",
    "        TN_last_AB = 0\n",
    "        for j in range(len(val_label_temp)):\n",
    "            label_next = abs(val_label_temp[j])\n",
    "            Comatose, Deceased, Delirious, Discharged, Normal, YYYYYY = val_temp[j][229], val_temp[j][230], val_temp[j][231], val_temp[j][232], val_temp[j][233], val_temp[j][234]\n",
    "\n",
    "            predicted_label = pred_y[j]\n",
    "            assert YYYYYY == 0\n",
    "            if predicted_label != label_next:\n",
    "                if predicted_label == 0: # FN .\n",
    "                    if Discharged == 1 or Normal == 1:\n",
    "                        FN_last_N += 1\n",
    "                    else:\n",
    "                        FN_last_AB += 1\n",
    "\n",
    "                else: #FP\n",
    "                    if Discharged == 1 or Normal == 1:\n",
    "                        FP_last_N += 1\n",
    "                    else:\n",
    "                        FP_last_AB += 1\n",
    "            else:\n",
    "                if predicted_label == 0: # TN\n",
    "                    if Discharged == 1 or Normal == 1:\n",
    "                        TN_last_N += 1\n",
    "                    else:\n",
    "                        TN_last_AB += 1\n",
    "\n",
    "                else: #TP\n",
    "                    if Discharged == 1 or Normal == 1:\n",
    "                        TP_last_N += 1\n",
    "                    else:\n",
    "                        TP_last_AB += 1\n",
    "\n",
    "\n",
    "        print(\"Validation AUROC: %.4f, PRAUC: %.4f, ACC: %.4f, PPV: %.4f, NPV: %.4f, Sensitivity: %.4f, Specificity: %.4f. Best threshold %.4f\" % (auroc, prauc, acc, ppv, npv, sens, spes, thres))\n",
    "        print('| TN: %d (%d/%d)' % (tn, TN_last_N, TN_last_AB), '| FP: %d (%d/%d)' % (fp, FP_last_N, FP_last_AB),\n",
    "          '| FN: %d (%d/%d)' % (fn, FN_last_N, FN_last_AB), '| TP: %d (%d/%d)' % (tp, TP_last_N, TP_last_AB),\n",
    "          '| Total: %d' % (tn + fp + fn + tp))\n",
    "\n",
    "        best_threshold_list_val.append(thres)\n",
    "        joblib.dump(gbm, './result/Added_V50_uncalibrated_lgb_split_'+str(SPLIT)+'_run_'+str(fold)+'.pkl')\n",
    "\n",
    "\n",
    "        ##### test before calibration\n",
    "\n",
    "        y_scores_before = gbm.predict_proba(test_temp)\n",
    "        y_scores_before = y_scores_before[:,1]\n",
    "#         print(y_scores_before[:50])\n",
    "        pred_y = [0.0] * len(y_scores_before)\n",
    "        for ind, value in enumerate(y_scores_before):\n",
    "            if value >= thres:\n",
    "                pred_y[ind] = 1.0\n",
    "        pred_y = np.array(pred_y)\n",
    "        auroc = roc_auc_score(y_score=y_scores_before, y_true=abs(test_label_temp))\n",
    "        prauc = average_precision_score(abs(test_label_temp), y_scores_before)\n",
    "        tn, fp, fn, tp = confusion_matrix(abs(test_label_temp), pred_y).ravel()\n",
    "        ppv = tp / (tp + fp)\n",
    "        npv = tn / (tn + fn)\n",
    "        sens = tp / (tp + fn)\n",
    "        spes = tn / (tn + fp)\n",
    "        acc = (tn + tp) / (tn + fp + fn + tp)\n",
    "        \n",
    "        ### analyze false postive ***\n",
    "        FP_num = 0\n",
    "        FP_num_3rd_acc_num = 0\n",
    "        for ind_test in range(len(test_label_temp)):\n",
    "            if int(pred_y[ind_test]) == 1 and int(abs(test_label_temp[ind_test])) != 1:\n",
    "                FP_num += 1\n",
    "                if ind_test < len(test_label_temp)-1 and patient_indicator[ind_test+1] == patient_indicator[ind_test] and int(abs(test_label_temp[ind_test+1])) == 1: \n",
    "                    FP_num_3rd_acc_num += 1\n",
    "                    \n",
    "        third_day_acc_in_FP.append(FP_num_3rd_acc_num/float(FP_num))\n",
    "        \n",
    "\n",
    "        FP_last_N = 0\n",
    "        FP_last_AB = 0\n",
    "        FN_last_N = 0\n",
    "        FN_last_AB = 0\n",
    "        TP_last_N = 0\n",
    "        TP_last_AB = 0\n",
    "        TN_last_N = 0\n",
    "        TN_last_AB = 0\n",
    "        for j in range(len(test_label_temp)):\n",
    "            label_next = abs(test_label_temp[j])\n",
    "            Comatose, Deceased, Delirious, Discharged, Normal, YYYYYY = test_temp[j][229], test_temp[j][230], test_temp[j][231], test_temp[j][232], test_temp[j][233], test_temp[j][234]\n",
    "\n",
    "            predicted_label = pred_y[j]\n",
    "            assert YYYYYY == 0\n",
    "            if predicted_label != label_next:\n",
    "                if predicted_label == 0: # FN ..\n",
    "                    if Discharged == 1 or Normal == 1:\n",
    "                        FN_last_N += 1\n",
    "                    else:\n",
    "                        FN_last_AB += 1\n",
    "\n",
    "                else: #FP\n",
    "                    if Discharged == 1 or Normal == 1:\n",
    "                        FP_last_N += 1\n",
    "                    else:\n",
    "                        FP_last_AB += 1\n",
    "\n",
    "            else:\n",
    "                if predicted_label == 0: # TN\n",
    "                    if Discharged == 1 or Normal == 1:\n",
    "                        TN_last_N += 1\n",
    "                    else:\n",
    "                        TN_last_AB += 1\n",
    "\n",
    "                else: #TP\n",
    "                    if Discharged == 1 or Normal == 1:\n",
    "                        TP_last_N += 1\n",
    "                    else:\n",
    "                        TP_last_AB += 1\n",
    "\n",
    "        print(\n",
    "        \"Before Calibration:   Test AUROC: %.4f, PRAUC: %.4f, ACC: %.4f, PPV: %.4f, NPV: %.4f, Sensitivity: %.4f, Specificity: %.4f, FP_3rd_day_acc: %.4f\" % (\n",
    "        auroc, prauc, acc, ppv, npv, sens, spes, FP_num_3rd_acc_num/float(FP_num)))   ##   ***\n",
    "        print('| TN: %d (%d/%d)' % (tn, TN_last_N, TN_last_AB), '| FP: %d (%d/%d)' % (fp, FP_last_N, FP_last_AB),\n",
    "          '| FN: %d (%d/%d)' % (fn, FN_last_N, FN_last_AB), '| TP: %d (%d/%d)' % (tp, TP_last_N, TP_last_AB),\n",
    "          '| Total: %d' % (tn + fp + fn + tp))\n",
    "\n",
    "#         before_temperature_ece = ECE_value(y_scores_before, abs(test_label_temp), BIN)\n",
    "        before_temperature_ece = brier_score_loss(abs(test_label_temp), y_scores_before, pos_label=1)\n",
    "        print('ECE Loss Before Calibration: %.8f' % before_temperature_ece)\n",
    "        ece_loss_before_cal.append(before_temperature_ece)\n",
    "        \n",
    "        auroc_result.append(auroc)\n",
    "        prauc_result.append(prauc)\n",
    "        acc_result.append(acc)\n",
    "        ppv_result.append(ppv)\n",
    "        npv_result.append(npv)\n",
    "        sens_result.append(sens)\n",
    "        spes_result.append(spes)\n",
    "        tn_result.append(tn)\n",
    "        tp_result.append(tp)\n",
    "        fn_result.append(fn)\n",
    "        fp_result.append(fp)\n",
    "\n",
    "        TN_last_N_result.append(TN_last_N)\n",
    "        TN_last_AB_result.append(TN_last_AB)\n",
    "        FP_last_N_result.append(FP_last_N)\n",
    "        FP_last_AB_result.append(FP_last_AB)\n",
    "        FN_last_N_result.append(FN_last_N)\n",
    "        FN_last_AB_result.append(FN_last_AB)\n",
    "        TP_last_N_result.append(TP_last_N)\n",
    "        TP_last_AB_result.append(TP_last_AB)\n",
    "        \n",
    "#         third_day_acc_in_FP.append(FP_num_3rd_acc_num/float(FP_num))   ##  ***\n",
    "\n",
    "        ##### test after calibration \n",
    "\n",
    "        calibrator = CalibratedClassifierCV(gbm, method='isotonic', cv='prefit')\n",
    "        calibrator.fit(val_temp, abs(val_label_temp))\n",
    "        \n",
    "        ################### need to recompute the threshold on validation set\n",
    "        y_scores_temp = calibrator.predict_proba(val_temp)\n",
    "        y_scores_temp = y_scores_temp[:,1]\n",
    "        fpr, tpr, threshold = roc_curve(abs(val_label_temp), y_scores_temp, pos_label=1)\n",
    "        max_ = 0\n",
    "        pos = 0\n",
    "        thres = 0\n",
    "        for i in range(len(fpr)):\n",
    "            sensitivity = tpr[i]\n",
    "            specificity = 1 - fpr[i]\n",
    "            if sensitivity + specificity - 1 > max_:\n",
    "                thres = threshold[i]\n",
    "                max_ = sensitivity + specificity - 1\n",
    "                pos = i\n",
    "        if Youden == False:\n",
    "            thres = 0.5\n",
    "        \n",
    "        ###################\n",
    "\n",
    "        y_scores_after = calibrator.predict_proba(test_temp)\n",
    "        y_scores_after = y_scores_after[:,1]\n",
    "#         print(y_scores_after[:50])\n",
    "        pred_y = [0.0] * len(y_scores_after)\n",
    "        for ind, value in enumerate(y_scores_after):\n",
    "            if value >= thres:\n",
    "                pred_y[ind] = 1.0\n",
    "        pred_y = np.array(pred_y)\n",
    "        auroc = roc_auc_score(y_score=y_scores_after, y_true=abs(test_label_temp))\n",
    "        prauc = average_precision_score(abs(test_label_temp), y_scores_after)\n",
    "        tn, fp, fn, tp = confusion_matrix(abs(test_label_temp), pred_y).ravel()\n",
    "        ppv = tp / (tp + fp)\n",
    "        npv = tn / (tn + fn)\n",
    "        sens = tp / (tp + fn)\n",
    "        spes = tn / (tn + fp)\n",
    "        acc = (tn + tp) / (tn + fp + fn + tp)\n",
    "\n",
    "        FP_last_N = 0\n",
    "        FP_last_AB = 0\n",
    "        FN_last_N = 0\n",
    "        FN_last_AB = 0\n",
    "        TP_last_N = 0\n",
    "        TP_last_AB = 0\n",
    "        TN_last_N = 0\n",
    "        TN_last_AB = 0\n",
    "        for j in range(len(test_label_temp)):\n",
    "            label_next = abs(test_label_temp[j])\n",
    "            Comatose, Deceased, Delirious, Discharged, Normal, YYYYYY = test_temp[j][229], test_temp[j][230], test_temp[j][231], test_temp[j][232], test_temp[j][233], test_temp[j][234]\n",
    "  \n",
    "            predicted_label = pred_y[j]\n",
    "            assert YYYYYY == 0\n",
    "            if predicted_label != label_next:\n",
    "                if predicted_label == 0: # FN ...\n",
    "                    if Discharged == 1 or Normal == 1:\n",
    "                        FN_last_N += 1\n",
    "                    else:\n",
    "                        FN_last_AB += 1\n",
    "\n",
    "                else: #FP\n",
    "                    if Discharged == 1 or Normal == 1:\n",
    "                        FP_last_N += 1\n",
    "                    else:\n",
    "                        FP_last_AB += 1\n",
    "\n",
    "            else:\n",
    "                if predicted_label == 0: # TN\n",
    "                    if Discharged == 1 or Normal == 1:\n",
    "                        TN_last_N += 1\n",
    "                    else:\n",
    "                        TN_last_AB += 1\n",
    "\n",
    "                else: #TP\n",
    "                    if Discharged == 1 or Normal == 1:\n",
    "                        TP_last_N += 1\n",
    "                    else:\n",
    "                        TP_last_AB += 1\n",
    "\n",
    "\n",
    "        print(\n",
    "        \"After Calibration:   Test AUROC: %.4f, PRAUC: %.4f, ACC: %.4f, PPV: %.4f, NPV: %.4f, Sensitivity: %.4f, Specificity: %.4f, Best threshold: %.4f\" % (\n",
    "        auroc, prauc, acc, ppv, npv, sens, spes, thres))\n",
    "        print('| TN: %d (%d/%d)' % (tn, TN_last_N, TN_last_AB), '| FP: %d (%d/%d)' % (fp, FP_last_N, FP_last_AB),\n",
    "          '| FN: %d (%d/%d)' % (fn, FN_last_N, FN_last_AB), '| TP: %d (%d/%d)' % (tp, TP_last_N, TP_last_AB),\n",
    "          '| Total: %d' % (tn + fp + fn + tp))\n",
    "\n",
    "        \n",
    "        prob_df_cal_before = pd.DataFrame({'y':abs(test_label_temp), 'y_hat': y_scores_before})\n",
    "        # binning the dataframe, so we can see success rates for bins of probability\n",
    "        bins = np.arange(0.05, 1.00, 0.05)\n",
    "        prob_df_cal_before.loc[:,'prob_bin'] = np.digitize(prob_df_cal_before['y_hat'], bins)\n",
    "        prob_df_cal_before.loc[:,'prob_bin_test'] = prob_df_cal_before['prob_bin'].replace(dict(zip(range(len(bins) + 1), list(bins) + [1.00])))\n",
    "\n",
    "        prob_df_cal_after = pd.DataFrame({'y':abs(test_label_temp), 'y_hat': y_scores_after})\n",
    "        # binning the dataframe, so we can see success rates for bins of probability\n",
    "        bins = np.arange(0.05, 1.00, 0.05)\n",
    "        prob_df_cal_after.loc[:,'prob_bin'] = np.digitize(prob_df_cal_after['y_hat'], bins)\n",
    "        prob_df_cal_after.loc[:,'prob_bin_test'] = prob_df_cal_after['prob_bin'].replace(dict(zip(range(len(bins) + 1), list(bins) + [1.00])))\n",
    "\n",
    "#         plt.figure(figsize=(12,9), dpi=150)\n",
    "#         plt.plot([0,1],[0,1], 'k--', label='ideal')\n",
    "\n",
    "#         # plotting calibration for lgbm\n",
    "#         calibration_y = prob_df_cal_before.groupby('prob_bin_test')['y'].mean()\n",
    "#         calibration_x = prob_df_cal_before.groupby('prob_bin_test')['y_hat'].mean()\n",
    "#         plt.plot(calibration_x, calibration_y, marker='o', label='LightGBM')\n",
    "\n",
    "\n",
    "#         calibration_y_test = prob_df_cal_after.groupby('prob_bin_test')['y'].mean()\n",
    "#         calibration_x_test = prob_df_cal_after.groupby('prob_bin_test')['y_hat'].mean()\n",
    "#         plt.plot(calibration_x_test, calibration_y_test, marker='o', label='LightGBM (Calibrated)')\n",
    "\n",
    "#         # legend and titles\n",
    "#         plt.title('Calibration plot for LightGBM')\n",
    "#         plt.xlabel('Predicted probability')\n",
    "#         plt.ylabel('Actual fraction of positives')\n",
    "#         plt.legend()\n",
    "        \n",
    "        np.save('./result/Added_V50_prediction_on_test_split_'+str(SPLIT)+'_run_'+str(fold)+'.npy', y_scores_after)\n",
    "        joblib.dump(calibrator, './result/Added_V50_calibrated_lgb_split_'+str(SPLIT)+'_run_'+str(fold)+'.pkl')\n",
    "\n",
    "\n",
    "        explainer = shap.TreeExplainer(gbm)\n",
    "        shap_values = explainer.shap_values(test_temp)\n",
    "        np.save('./result/Added_V50_shap_values_split_'+ str(SPLIT)+'_run_'+str(fold)+'.npy', shap_values)\n",
    "        fold += 1\n",
    "\n",
    "#         after_temperature_ece = ECE_value(y_scores_after, abs(test_label_temp), BIN)\n",
    "        after_temperature_ece = brier_score_loss(abs(test_label_temp), y_scores_after, pos_label=1)\n",
    "        print('ECE Loss After Calibration: %.8f' % after_temperature_ece)\n",
    "        ece_loss_after_cal.append(after_temperature_ece)\n",
    "\n",
    "    result_dict = {'PRAUC': prauc_result, 'AUROC': auroc_result, 'ACC': acc_result, 'Recall': sens_result, 'Specificity': spes_result, 'PPV': ppv_result, 'NPV':npv_result, 'TN': tn_result, 'TP': tp_result, 'FN':fn_result, 'FP':fp_result, 'TN_last_N_result':TN_last_N_result,  'TN_last_AB_result':TN_last_AB_result, 'FN_last_N_result':FN_last_N_result,  'FN_last_AB_result':FN_last_AB_result, 'Threshold':best_threshold_list_val}\n",
    "    np.save('./result/Added_V50_summary_result_split_'+str(SPLIT)+'.npy', result_dict)\n",
    "\n",
    "    final_auroc_result.extend(auroc_result)\n",
    "    final_prauc_result.extend(prauc_result)\n",
    "    final_acc_result.extend(acc_result)\n",
    "    final_ppv_result.extend(ppv_result)\n",
    "    final_npv_result.extend(npv_result)\n",
    "    final_sens_result.extend(sens_result)\n",
    "    final_spes_result.extend(spes_result)\n",
    "\n",
    "    final_tn_result.extend(tn_result)\n",
    "    final_fp_result.extend(fp_result)\n",
    "    final_fn_result.extend(fn_result)\n",
    "    final_tp_result.extend(tp_result)\n",
    "\n",
    "    final_TN_last_N_result.extend(TN_last_N_result)\n",
    "    final_TN_last_AB_result.extend(TN_last_AB_result)\n",
    "    final_FP_last_N_result.extend(FP_last_N_result)\n",
    "    final_FP_last_AB_result.extend(FP_last_AB_result)\n",
    "    final_FN_last_N_result.extend(FN_last_N_result)\n",
    "    final_FN_last_AB_result.extend(FN_last_AB_result)\n",
    "    final_TP_last_N_result.extend(TP_last_N_result)\n",
    "    final_TP_last_AB_result.extend(TP_last_AB_result)\n",
    "\n",
    "    final_best_threshold_list_val.extend(best_threshold_list_val)\n",
    "    final_ece_loss_before_cal.extend(ece_loss_before_cal)\n",
    "    final_ece_loss_after_cal.extend(ece_loss_after_cal)\n",
    "    \n",
    "    final_3rd_day_acc_in_FP.extend(third_day_acc_in_FP)  ## ***\n",
    "        \n",
    "    SPLIT += 1\n",
    "\n",
    "print('AUROC mean %.4f,  std %.4f' % (np.mean(final_auroc_result), np.std(final_auroc_result)))\n",
    "print('PRAUC mean %.4f,  std %.4f' % (np.mean(final_prauc_result), np.std(final_prauc_result)))\n",
    "print('ACCURACY mean %.4f,  std %.4f' % (np.mean(final_acc_result), np.std(final_acc_result)))\n",
    "print('PPV mean %.4f,  std %.4f' % (np.mean(final_ppv_result), np.std(final_ppv_result)))\n",
    "print('NPV mean %.4f,  std %.4f' % (np.mean(final_npv_result), np.std(final_npv_result)))\n",
    "print('RECALL mean %.4f,  std %.4f' % (np.mean(final_sens_result), np.std(final_sens_result)))\n",
    "print('SPESIFICITY mean %.4f,  std %.4f' % (np.mean(final_spes_result), np.std(final_spes_result)))\n",
    "\n",
    "print('\\nTN_last_N mean %.4f,  std %.4f' % (np.mean(final_TN_last_N_result), np.std(final_TN_last_N_result)))\n",
    "print('TN_last_AB mean %.4f,  std %.4f' % (np.mean(final_TN_last_AB_result), np.std(final_TN_last_AB_result)))\n",
    "print('FP_last_N mean %.4f,  std %.4f' % (np.mean(final_FP_last_N_result), np.std(final_FP_last_N_result)))\n",
    "print('FP_last_AB mean %.4f,  std %.4f' % (np.mean(final_FP_last_AB_result), np.std(final_FP_last_AB_result)))\n",
    "print('FN_last_N mean %.4f,  std %.4f' % (np.mean(final_FN_last_N_result), np.std(final_FN_last_N_result)))\n",
    "print('FN_last_AB mean %.4f,  std %.4f' % (np.mean(final_FN_last_AB_result), np.std(final_FN_last_AB_result)))\n",
    "print('TP_last_N mean %.4f,  std %.4f' % (np.mean(final_TP_last_N_result), np.std(final_TP_last_N_result)))\n",
    "print('TP_last_AB mean %.4f,  std %.4f' % (np.mean(final_TP_last_AB_result), np.std(final_TP_last_AB_result)))\n",
    "\n",
    "print('final_3rd_day_acc_in_FP %.4f,  std %.4f' % (np.mean(final_3rd_day_acc_in_FP), np.std(final_3rd_day_acc_in_FP)))   ## ***\n",
    "\n",
    "print('\\nBrier score before calibration mean %.4f, std %.4f' % (np.mean(final_ece_loss_before_cal), np.std(final_ece_loss_before_cal)))\n",
    "print('Brier score after calibration mean %.4f, std %.4f' % (np.mean(final_ece_loss_after_cal), np.std(final_ece_loss_after_cal)))\n",
    "\n",
    "\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m-h, m+h\n",
    "\n",
    "\n",
    "auroc_list = []\n",
    "prauc_list = []\n",
    "acc_list = []\n",
    "recall_list = []\n",
    "spes_list = []\n",
    "ppv_list = []\n",
    "npv_list = []\n",
    "\n",
    "\n",
    "for SPLIT in range(RAND_TIME):\n",
    "    result_dict = np.load('./result/Added_V50_summary_result_split_'+str(SPLIT)+'.npy', allow_pickle=True).item()\n",
    "    auroc_list.extend(result_dict['AUROC'])\n",
    "    prauc_list.extend(result_dict['PRAUC'])\n",
    "    acc_list.extend(result_dict['ACC'])\n",
    "    recall_list.extend(result_dict['Recall'])\n",
    "    spes_list.extend(result_dict['Specificity'])\n",
    "    ppv_list.extend(result_dict['PPV'])\n",
    "    npv_list.extend(result_dict['NPV'])\n",
    "\n",
    "\n",
    "var = \"%\"\n",
    "\n",
    "m, b, t = mean_confidence_interval(auroc_list)\n",
    "print('AUROC: %.3f (%.3f, %.3f) ' % (m, b, t))\n",
    "\n",
    "m, b, t = mean_confidence_interval(prauc_list)\n",
    "print('PRAUC: %.3f (%.3f, %.3f) ' % (m, b, t))\n",
    "\n",
    "m, b, t = mean_confidence_interval(acc_list)\n",
    "print('Accuracy: %.3f (%.3f, %.3f) ' % (m, b, t))\n",
    "\n",
    "m, b, t = mean_confidence_interval(recall_list)\n",
    "print('Recall: %.3f (%.3f, %.3f) ' % (m, b, t))\n",
    "\n",
    "m, b, t = mean_confidence_interval(spes_list)\n",
    "print('Specificity: %.3f (%.3f, %.3f) ' % (m, b, t))\n",
    "\n",
    "m, b, t = mean_confidence_interval(ppv_list)\n",
    "print('PPV: %.3f (%.3f, %.3f) ' % (m, b, t))\n",
    "\n",
    "m, b, t = mean_confidence_interval(npv_list)\n",
    "print('NPV: %.3f (%.3f, %.3f) ' % (m, b, t))\n",
    "\n",
    "m, b, t = mean_confidence_interval(final_3rd_day_acc_in_FP)\n",
    "print('final_3rd_day_acc_in_FP: %.3f (%.3f, %.3f) ' % (m, b, t))\n",
    "\n",
    "m, b, t = mean_confidence_interval(final_ece_loss_before_cal)\n",
    "print('final_ece_loss_before_cal: %.3f (%.3f, %.3f) ' % (m, b, t))\n",
    "\n",
    "m, b, t = mean_confidence_interval(final_ece_loss_after_cal)\n",
    "print('final_ece_loss_after_cal: %.3f (%.3f, %.3f) ' % (m, b, t))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
